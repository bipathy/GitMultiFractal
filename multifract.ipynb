{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3.13 -m venv /Users/jethro/Documents/Code/GitOak/MultiFractal/multifractal_env\n",
    "source /Users/jethro/Documents/Code/GitOak/MultiFractal/multifractal_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /Users/jethro/Documents/Code/GitOak/MultiFractal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "Step 2 will be to install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install numpy pandas matplotlib mfdaf nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we need to extract time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Define data directory\n",
    "data_dir = \"/Users/jethro/Documents/Code/GitOak/MultiFractal\"\n",
    "output_dir = \"/Users/jethro/Documents/Code/GitOak/MultiFractal/extracted_time_series\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to extract mean time-series for each subject\n",
    "def extract_time_series(subject_id, mask_path=None):\n",
    "    # Adjust filename pattern to match actual file names\n",
    "    subject_path = os.path.join(data_dir, subject_id, \"func\", \n",
    "                                f\"{subject_id}_task-bilateralfingertapping_echo-1_bold.nii.gz\")\n",
    "    \n",
    "    if not os.path.exists(subject_path):\n",
    "        raise FileNotFoundError(f\"File not found: {subject_path}\")\n",
    "    \n",
    "    img = nib.load(subject_path)\n",
    "    data = img.get_fdata()\n",
    "    \n",
    "    # If mask is provided, apply it\n",
    "    if mask_path:\n",
    "        mask = nib.load(mask_path).get_fdata()\n",
    "        data = data[mask > 0]\n",
    "    \n",
    "    # Average time-series across voxels\n",
    "    time_series = data.mean(axis=(0, 1, 2))  # Adjust if using a mask\n",
    "    return time_series\n",
    "\n",
    "# Loop through subjects\n",
    "for sub in range(2, 14):  # sub-02 to sub-13\n",
    "    sub_id = f\"sub-{sub:02d}\"\n",
    "    print(f\"Processing {sub_id}...\")\n",
    "    try:\n",
    "        time_series = extract_time_series(sub_id)\n",
    "        np.savetxt(os.path.join(output_dir, f\"{sub_id}_time_series.csv\"), time_series, delimiter=\",\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, we proceed with MultiFractal Analysis on the data using analytics software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# install dependenies for MultiFractal Analysis - MF-DFA\n",
    "! pip install MFDFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use MFDFA to analyze the extracted data. Results for Hurst exponents (hurst), scaling exponents (tau), singularity strengths (alpha), and multifractal spectra (f(α)) are saved as .csv files. Plots of the multifractal spectrum are saved for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from MFDFA import MFDFA\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Define directories\n",
    "time_series_dir = \"/Users/jethro/Documents/Code/GitOak/MultiFractal/extracted_time_series\"\n",
    "output_dir = \"/Users/jethro/Documents/Code/GitOak/MultiFractal/multifractal_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# MF-DFA parameters\n",
    "scale_min, scale_max = 10, 500  # Minimum and maximum scales\n",
    "\n",
    "def compute_Hq(Fq, scales):\n",
    "    num_q = Fq.shape[1]\n",
    "    Hq = np.zeros(num_q)\n",
    "    log_scales = np.log2(scales)\n",
    "    \n",
    "    for i in range(num_q):\n",
    "        log_Fq = np.log2(Fq[:, i])\n",
    "        # Handle any invalid values\n",
    "        valid = np.isfinite(log_Fq)\n",
    "        if np.sum(valid) < 2:\n",
    "            Hq[i] = np.nan\n",
    "            continue\n",
    "        # Perform linear regression\n",
    "        slope, _, _, _, _ = linregress(log_scales[valid], log_Fq[valid])\n",
    "        Hq[i] = slope\n",
    "    return Hq\n",
    "\n",
    "def compute_singularity_spectrum(q, tau):\n",
    "    # Remove NaN values\n",
    "    valid = ~np.isnan(tau)\n",
    "    q = q[valid]\n",
    "    tau = tau[valid]\n",
    "    \n",
    "    # Fit a cubic spline to tau(q)\n",
    "    spline = UnivariateSpline(q, tau, k=3, s=0)\n",
    "    # Compute derivative of tau with respect to q\n",
    "    alpha = spline.derivative()(q)\n",
    "    # Compute f(α) as q*α - τ(q)\n",
    "    f_alpha = q * alpha - tau\n",
    "    return alpha, f_alpha\n",
    "\n",
    "def perform_mfdfa(file_path, output_path):\n",
    "    # Load time-series data\n",
    "    time_series = np.loadtxt(file_path)\n",
    "    \n",
    "    # Define scales and q_values\n",
    "    scales = np.logspace(np.log10(scale_min), np.log10(scale_max), num=20, base=10).astype(int)\n",
    "    q_values = np.arange(-5, 6, 1)\n",
    "    q_values = q_values[q_values != 0]  # Exclude q=0\n",
    "    \n",
    "    # Perform MF-DFA\n",
    "    # Unpack the returned fluctuation functions\n",
    "    Fq = MFDFA(time_series, scales, q=q_values)[0]\n",
    "    \n",
    "    # Verify Fq is a NumPy array\n",
    "    print(f\"Fq shape: {Fq.shape}\")\n",
    "    \n",
    "    # Compute Hq\n",
    "    Hq = compute_Hq(Fq, scales)\n",
    "    \n",
    "    # Calculate tau(q)\n",
    "    tau = q_values * Hq - 1\n",
    "    \n",
    "    # Compute singularity spectrum\n",
    "    alpha, f_alpha = compute_singularity_spectrum(q_values, tau)\n",
    "    \n",
    "    # Save results\n",
    "    np.savetxt(os.path.join(output_path, \"Hq.csv\"), Hq, delimiter=\",\")\n",
    "    np.savetxt(os.path.join(output_path, \"tau.csv\"), tau, delimiter=\",\")\n",
    "    np.savetxt(os.path.join(output_path, \"alpha.csv\"), alpha, delimiter=\",\")\n",
    "    np.savetxt(os.path.join(output_path, \"f_alpha.csv\"), f_alpha, delimiter=\",\")\n",
    "    \n",
    "    # Plot the multifractal spectrum\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(alpha, f_alpha, '-o')\n",
    "    plt.xlabel('Singularity Strength (α)')\n",
    "    plt.ylabel('Multifractal Spectrum (f(α))')\n",
    "    plt.title(f'Multifractal Spectrum for {os.path.basename(file_path)}')\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_path, \"multifractal_spectrum.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Loop through extracted time-series files\n",
    "for file_name in os.listdir(time_series_dir):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        subject_id = file_name.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should produce fluctuation and correlation functions and diagrams for the processed data. The fact that the code seems to have run quickly without any output is concerning, though. The output folder remains empty at the moment, but I'm hopeful that the files are simply rendering and should populate shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking like the process is simply taking a long time to run, and because VSCode handles python scripts through a kernel solver, they don't show up in the processes page of actvity monitor, but the network acivity still shows a long-running python task which appears to still be working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
